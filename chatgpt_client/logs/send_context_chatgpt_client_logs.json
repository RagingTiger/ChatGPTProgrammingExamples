[
  {
    "createdAt": 1673792987529,
    "completionMode": "freeform",
    "prompt": "write an example in go programming language showing how to use previous message/response pairs to send to chatgpt api",
    "suffix": null,
    "instruction": "",
    "completion": "\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n\t\"bytes\"\n)\n\nfunc main() {\n\turl := \"https://api.chatgpt.com/v2/message\"\n\n\t//Previous message/response pair\n\tprevMessage := \"Hello\"\n\tprevResponse := \"Hi there!\"\n\n\t//Create the payload\n\tpayload := []byte(`{\"prompt\": \"` + prevMessage + `\", \"context\": [{\"previous_message\": \"` + prevMessage + `\", \"previous_response\": \"` + prevResponse + `\"}]}`)\n\n\tclient := &http.Client{}\n\n\t//Create the request\n\treq, err := http.NewRequest(\"POST\", url, bytes.NewBuffer(payload))\n\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n\n\t//Set request headers\n\treq.Header.Set(\"Content-Type\", \"application/json\")\n\treq.Header.Set(\"Authorization\", \"Bearer <YourAPIKeyHere>\")\n\n\t//Make the request\n\tresp, err := client.Do(req)\n\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n\n\t//Read the response\n\tbody, err := ioutil.ReadAll(resp.Body)\n\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n\n\t//Print the response\n\tfmt.Println(string(body))\n}",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  },
  {
    "createdAt": 1673792919944,
    "completionMode": "freeform",
    "prompt": "can previous message/response pairs be sent to chatgpt as context",
    "suffix": null,
    "instruction": "",
    "completion": "?\n\nYes, previous message/response pairs can be sent to ChatGPT as context. ChatGPT is designed to be able to use previous conversations as context to generate more natural and appropriate responses.",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  },
  {
    "createdAt": 1673792871479,
    "completionMode": "freeform",
    "prompt": "how to send context to chatgpt api\n",
    "suffix": null,
    "instruction": "",
    "completion": "\nTo send context to ChatGPT API, you will need to make an HTTP POST request to the /context endpoint, passing the context as a JSON object in the request body. The JSON object should have the following format:\n\n```\n{\n  \"context\": \"<your_context_text>\"\n}\n```\n\nIf the request is successful, the response will contain a unique ID that can be used to retrieve the response from the /response endpoint.",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  },
  {
    "createdAt": 1673792846387,
    "completionMode": "freeform",
    "prompt": "can chatgpt api remember previous message history  in the same session\n",
    "suffix": null,
    "instruction": "",
    "completion": "\nNo, the ChatGPT API does not remember previous message history in the same session. Each new request to the API will start a new conversation with no context from the previous conversation.",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  },
  {
    "createdAt": 1673792824327,
    "completionMode": "freeform",
    "prompt": "can chatgpt remember previous message history  in the same session\n\n\nNo, ChatGPT cannot remember previous message history.",
    "suffix": null,
    "instruction": "",
    "completion": " It is a single shot model and does not maintain any memory between messages.",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  },
  {
    "createdAt": 1673792813707,
    "completionMode": "freeform",
    "prompt": "can chatgpt remember previous message history \n",
    "suffix": null,
    "instruction": "",
    "completion": "\nNo, ChatGPT cannot remember previous message history.",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  },
  {
    "createdAt": 1673792773327,
    "completionMode": "freeform",
    "prompt": "how to include previous message history in chatgpt api call",
    "suffix": null,
    "instruction": "",
    "completion": "\n\nChatGPT does not currently support the inclusion of previous message history in API calls. However, you can use a custom model to store and access previous messages. This would require you to create a custom model that is trained on your previous message history.",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  },
  {
    "createdAt": 1673792684669,
    "completionMode": "freeform",
    "prompt": "Can you write the previous code to include the maximum previous messages stored in history and also a configuration file to store all the necessary api request values in YML  in the go programming language",
    "suffix": null,
    "instruction": "",
    "completion": "\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"io/ioutil\"\n\t\"gopkg.in/yaml.v2\"\n)\n\ntype Config struct {\n\tToken string\n\tMaxHistory int\n}\n\nfunc main() {\n\t// Read configuration file\n\tyamlFile, err := ioutil.ReadFile(\"config.yml\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tvar config Config\n\terr = yaml.Unmarshal(yamlFile, &config)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Request messages\n\turl := fmt.Sprintf(\"https://api.example.com/messages?token=%s&limit=%d\", config.Token, config.MaxHistory)\n\tresp, err := http.Get(url)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer resp.Body.Close()\n\n\t// Read messages\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tvar messages []string\n\terr = json.Unmarshal(body, &messages)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Print messages\n\tfor _, msg := range messages {\n\t\tfmt.Println(msg)\n\t}\n\n}",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  },
  {
    "createdAt": 1673792640525,
    "completionMode": "freeform",
    "prompt": "Can you write the previous code to include the maximum previous messages stored in history and also a configuration file to store all the necessary api request values in YML",
    "suffix": null,
    "instruction": "",
    "completion": " format?\n\nimport requests\nimport yaml\n\n# Load configuration values from configuration file\nconfig = yaml.safe_load(open('config.yml'))\nAPI_URL = config['api_url']\nMAX_HISTORY_MESSAGES = config['max_history_messages']\n\n# Get all previous messages\nmessages = requests.get(API_URL + \"/messages/history?max_messages=\" + MAX_HISTORY_MESSAGES).json()\n\n# Print out all the messages\nfor message in messages:\n    print(message)",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  },
  {
    "createdAt": 1673791826813,
    "completionMode": "freeform",
    "prompt": "write a chatgpt api client with an interactive interpreter prompt that takes input from the user and sends it to openai in the programming language go",
    "suffix": null,
    "instruction": "",
    "completion": "\n\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"os\"\n\t\"strings\"\n)\n\nconst openaiEndpoint = \"https://api.openai.com/v1/engines/chatbot/completions\"\n\n// RequestBody is the json structure for the request body sent to OpenAI\ntype RequestBody struct {\n\tPrompt string `json:\"prompt\"`\n\tMaxTokens int `json:\"max_tokens\"`\n\tTemperature float32 `json:\"temperature\"`\n\tTopP float32 `json:\"top_p\"`\n\tN int `json:\"n\"`\n}\n\nfunc main() {\n\tfmt.Println(\"Welcome to OpenAI ChatGPT API Client\")\n\n\t// Get the OpenAI API key\n\tapiKey := os.Getenv(\"OPENAI_API_KEY\")\n\tif apiKey == \"\" {\n\t\tfmt.Println(\"Please provide the OpenAI API key as an environment variable\")\n\t\tos.Exit(1)\n\t}\n\n\t// Start the interactive prompt\n\tfmt.Println(\"Type your query below and press enter to submit:\")\n\tfor {\n\t\t// Read the input from the user\n\t\tvar query string\n\t\tfmt.Scanln(&query)\n\n\t\t// Create the request body\n\t\trequestBody := RequestBody{\n\t\t\tPrompt: query,\n\t\t\tMaxTokens: 100,\n\t\t\tTemperature: 0.7,\n\t\t\tTopP: 0.9,\n\t\t\tN: 3,\n\t\t}\n\n\t\t// Encode the request body as json\n\t\trequestBodyBytes, err := json.Marshal(requestBody)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error encoding json: %v\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\t// Create the http client\n\t\tclient := &http.Client{}\n\n\t\t// Create the request\n\t\treq, err := http.NewRequest(\"POST\", openaiEndpoint, strings.NewReader(string(requestBodyBytes)))\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error creating http request: %v\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\t// Add the API key to the request\n\t\treq.Header.Add(\"Authorization\", fmt.Sprintf(\"Bearer %s\", apiKey))\n\n\t\t// Send the request\n\t\tresp, err := client.Do(req)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error sending http request: %v\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\t// Read the response\n\t\trespBytes, err := ioutil.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error reading http response: %v\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\t// Decode the response\n\t\tvar respBody struct {\n\t\t\tChoices []struct {\n\t\t\t\tText string `json:\"text\"`\n\t\t\t\tIndex int `json:\"index\"`\n\t\t\t} `json:\"choices\"`\n\t\t}\n\t\terr = json.Unmarshal(respBytes, &respBody)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error decoding response: %v\\n\", err)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\t// Print the response\n\t\tfmt.Println(\"Response:\")\n\t\tfor _, c := range respBody.Choices {\n\t\t\tfmt.Printf(\"%d: %s\\n\", c.Index, c.Text)\n\t\t}\n\t}\n}",
    "stopSequence": [],
    "startSequence": "",
    "restartSequence": "",
    "model": "text-davinci-003",
    "responseLength": 3959,
    "temperature": 0.7,
    "topP": 1,
    "frequencyPenalty": 0,
    "presencePenalty": 0,
    "bestOf": 1
  }
]